{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnYq3pS3gmIE",
        "outputId": "fb7f5d67-6193-46ee-c0d9-f0f98aa6518b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ratelimit in /usr/local/lib/python3.10/dist-packages (2.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install ratelimit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d36ZmWEWhW0x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "import google.generativeai as genai\n",
        "from ratelimit import limits, sleep_and_retry\n",
        "\n",
        "logs_folder = \"logs\"\n",
        "models_folder = \"models\"\n",
        "data_folder = \"data\"\n",
        "broken_data_folder = \"broken_data\"\n",
        "\n",
        "for folder in [logs_folder, models_folder, data_folder, broken_data_folder]:\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ujcLyIwIhXZ_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class CoderAgent:\n",
        "    def __init__(self, num_states, num_actions, epsilon=0.75, alpha=0.5, gamma=0.8):\n",
        "        self.q_table = np.zeros((num_states, num_actions))\n",
        "        self.epsilon = epsilon\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma \n",
        "        self.actions = [\n",
        "            \"Remover linhas com valores nulos em 'df'\",\n",
        "            \"Preencher valores nulos em colunas numéricas de 'df' com a média\",\n",
        "            \"Preencher valores nulos em 'df' com zero\",\n",
        "            \"Remover colunas com muitos valores nulos em 'df'\",\n",
        "        ]\n",
        "        self.action_counts = np.zeros(num_actions)\n",
        "\n",
        "    def select_action(self, state_index):\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            action_index = np.random.randint(len(self.actions))\n",
        "        else:\n",
        "            action_index = np.argmax(self.q_table[state_index])\n",
        "        self.action_counts[action_index] += 1\n",
        "        return action_index\n",
        "\n",
        "    def update(self, state_index, action_index, reward, next_state_index):\n",
        "        best_next_action = np.argmax(self.q_table[next_state_index])\n",
        "        td_target = reward + self.gamma * self.q_table[next_state_index, best_next_action]\n",
        "        td_error = td_target - self.q_table[state_index, action_index]\n",
        "        self.q_table[state_index, action_index] += self.alpha * td_error\n",
        "\n",
        "    def decay_epsilon(self, decay_rate, min_epsilon):\n",
        "        self.epsilon = max(min_epsilon, self.epsilon * decay_rate)\n",
        "\n",
        "\n",
        "class ReviewerAgent:\n",
        "    def __init__(self, num_states, num_actions, epsilon=0.75, alpha=0.5, gamma=0.8):\n",
        "        self.q_table = np.zeros((num_states, num_actions))\n",
        "        self.epsilon = epsilon\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.actions = [\n",
        "            \"O código está correto\",\n",
        "            \"O código tem erros de sintaxe\",\n",
        "            \"O código não resolve o problema\",\n",
        "            \"O código é ineficiente\",\n",
        "        ]\n",
        "        self.action_counts = np.zeros(num_actions)\n",
        "\n",
        "    def select_action(self, state_index):\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            action_index = np.random.randint(len(self.actions))\n",
        "        else:\n",
        "            action_index = np.argmax(self.q_table[state_index])\n",
        "        self.action_counts[action_index] += 1\n",
        "        return action_index\n",
        "\n",
        "    def update(self, state_index, action_index, reward, next_state_index, next_action_index):\n",
        "        td_target = reward + self.gamma * self.q_table[next_state_index, next_action_index]\n",
        "        td_error = td_target - self.q_table[state_index, action_index]\n",
        "        self.q_table[state_index, action_index] += self.alpha * td_error\n",
        "\n",
        "    def decay_epsilon(self, decay_rate, min_epsilon):\n",
        "        self.epsilon = max(min_epsilon, self.epsilon * decay_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WKfKfQI3hZMp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class DatasetDisruptor:\n",
        "    def __init__(self, seed=None):\n",
        "        self.seed = seed\n",
        "        if seed is not None:\n",
        "            np.random.seed(seed)\n",
        "\n",
        "    def introduce_missing_values(self, df, missing_fraction=0.1):\n",
        "        df_broken = df.copy()\n",
        "        n_total = df.size\n",
        "        n_missing = int(n_total * min(missing_fraction, 0.2))\n",
        "        indices = [(row, col) for row in range(df.shape[0]) for col in range(df.shape[1])]\n",
        "        if n_missing > 0:\n",
        "            missing_indices = np.random.choice(len(indices), n_missing, replace=False)\n",
        "            for idx in missing_indices:\n",
        "                row, col = indices[idx]\n",
        "                df_broken.iat[row, col] = np.nan\n",
        "        return df_broken\n",
        "\n",
        "    def introduce_column_missing(self, df, col_missing_fraction=0.1):\n",
        "        df_broken = df.copy()\n",
        "        n_cols = df.shape[1]\n",
        "        n_cols_missing = int(n_cols * min(col_missing_fraction, 0.1))\n",
        "        if n_cols_missing > 0:\n",
        "            cols_to_break = np.random.choice(df.columns, size=n_cols_missing, replace=False)\n",
        "            df_broken[cols_to_break] = np.nan\n",
        "        return df_broken\n",
        "\n",
        "    def introduce_row_missing(self, df, row_missing_fraction=0.05):\n",
        "        df_broken = df.copy()\n",
        "        n_rows = df.shape[0]\n",
        "        n_rows_missing = int(n_rows * min(row_missing_fraction, 0.05))\n",
        "        if n_rows_missing > 0:\n",
        "            rows_to_break = np.random.choice(df.index, size=n_rows_missing, replace=False)\n",
        "            df_broken.loc[rows_to_break] = np.nan\n",
        "        return df_broken\n",
        "\n",
        "    def add_noise(self, df, noise_fraction=0.02, noise_level=0.05):\n",
        "        df_broken = df.copy()\n",
        "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "        n_total = df[numeric_cols].size\n",
        "        n_noisy = int(n_total * min(noise_fraction, 0.02))\n",
        "\n",
        "        if n_noisy > 0:\n",
        "            indices = [(row, col) for row in df.index for col in numeric_cols]\n",
        "            noisy_indices = np.random.choice(len(indices), n_noisy, replace=False)\n",
        "            for idx in noisy_indices:\n",
        "                row, col = indices[idx]\n",
        "                original_value = df_broken.at[row, col]\n",
        "                if pd.notnull(original_value):\n",
        "                    df_broken.at[row, col] += np.random.normal(0, noise_level)\n",
        "        return df_broken\n",
        "\n",
        "    def break_dataset(self, df, missing_fraction=0.1, col_missing_fraction=0.1, row_missing_fraction=0.05, noise_fraction=0.02, noise_level=0.05):\n",
        "        df_broken = self.introduce_missing_values(df, missing_fraction)\n",
        "        df_broken = self.introduce_column_missing(df_broken, col_missing_fraction)\n",
        "        df_broken = self.introduce_row_missing(df_broken, row_missing_fraction)\n",
        "        df_broken = self.add_noise(df_broken, noise_fraction, noise_level)\n",
        "        return df_broken\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EFIDcZKnha_u"
      },
      "outputs": [],
      "source": [
        "class LLMClient:\n",
        "    def __init__(self, api_key):\n",
        "        genai.configure(api_key=api_key)\n",
        "\n",
        "    def generate_code(self, prompt):\n",
        "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "        response = model.generate_content(prompt)\n",
        "        code = response.text\n",
        "        return code.strip()\n",
        "\n",
        "    def generate_feedback(self, prompt):\n",
        "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "        response = model.generate_content(prompt)\n",
        "        feedback = response.text\n",
        "        return feedback.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Soam4XOahdNn"
      },
      "outputs": [],
      "source": [
        "def prepare_broken_data():\n",
        "    disruptor = DatasetDisruptor()\n",
        "\n",
        "    data_files = [f for f in os.listdir(data_folder) if f.endswith('.csv')]\n",
        "    if len(data_files) == 0:\n",
        "        df_example = pd.DataFrame({\n",
        "            \"A\":[1,2,3,4,5],\n",
        "            \"B\":[10,20,30,40,50],\n",
        "            \"C\":[100,200,300,400,500]\n",
        "        })\n",
        "        df_example.to_csv(os.path.join(data_folder, \"example.csv\"), index=False)\n",
        "        data_files = [\"example.csv\"]\n",
        "\n",
        "    broken_files = [f for f in os.listdir(broken_data_folder) if f.endswith('.csv')]\n",
        "    if len(broken_files) == 0:\n",
        "        for filename in data_files:\n",
        "            filepath = os.path.join(data_folder, filename)\n",
        "            df = pd.read_csv(filepath)\n",
        "            df_broken = disruptor.break_dataset(df)\n",
        "            output_filepath = os.path.join(broken_data_folder, filename)\n",
        "            df_broken.to_csv(output_filepath, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G3JSLNpAhe5c"
      },
      "outputs": [],
      "source": [
        "class DataCleaningEnv:\n",
        "    def __init__(self, llm_client, data_folder='broken_data'):\n",
        "        self.llm_client = llm_client\n",
        "        self.data_folder = data_folder\n",
        "        self.data_files = [os.path.join(data_folder, f) for f in os.listdir(data_folder) if f.endswith('.csv')]\n",
        "        if len(self.data_files) == 0:\n",
        "            raise FileNotFoundError(\"Nenhum arquivo encontrado em 'broken_data'. Rode prepare_broken_data() primeiro.\")\n",
        "        self.current_file_index = -1\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_file_index = (self.current_file_index + 1) % len(self.data_files)\n",
        "        data_file = self.data_files[self.current_file_index]\n",
        "        self.df = pd.read_csv(data_file)\n",
        "        self.original_df = self.df.copy()\n",
        "        self.state = self._get_state()\n",
        "        self.missing_percent_before_feedback = self.df.isnull().mean().mean()\n",
        "        return self.state\n",
        "\n",
        "    def _get_state(self):\n",
        "        missing_percent = self.df.isnull().mean().mean()\n",
        "        if np.isnan(missing_percent):\n",
        "            missing_percent = 1.0\n",
        "        return np.array([missing_percent])\n",
        "\n",
        "    def step_coder(self, code, action_index):\n",
        "        fallback_actions = {\n",
        "            0: (\n",
        "                \"if not df.dropna().empty:\\n\"\n",
        "                \"    df.dropna(inplace=True)\\n\"\n",
        "                \"else:\\n\"\n",
        "                \"    pass\"\n",
        "            ),\n",
        "            1: (\n",
        "                \"numeric_cols = df.select_dtypes(include=[np.number]).columns\\n\"\n",
        "                \"df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\"\n",
        "            ),\n",
        "            2: \"df.fillna(0, inplace=True)\",\n",
        "            3: (\n",
        "                \"threshold = int(0.8 * df.shape[0])\\n\"\n",
        "                \"df.dropna(axis=1, thresh=threshold, inplace=True)\"\n",
        "            ),\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            if 'input(' in code or 'import os' in code:\n",
        "                raise ValueError(\"O código gerado contém chamadas não permitidas.\")\n",
        "            safe_globals = {'df': self.df.copy(), 'pd': pd, 'np': np, '__builtins__': {}}\n",
        "            safe_locals = {}\n",
        "            exec(compile(code, '<string>', 'exec'), safe_globals, safe_locals)\n",
        "\n",
        "            if 'df' in safe_globals:\n",
        "                self.df = safe_globals['df']\n",
        "            elif 'df' in safe_locals:\n",
        "                self.df = safe_locals['df']\n",
        "\n",
        "            reward = self._calculate_reward_coder()\n",
        "            done = self._check_done()\n",
        "            return self._get_state(), reward, done, {}\n",
        "        except Exception:\n",
        "            fallback_code = fallback_actions.get(action_index, \"\")\n",
        "            exec(fallback_code, {'df': self.df, 'pd': pd, 'np': np})\n",
        "            reward = self._calculate_reward_coder()\n",
        "            done = self._check_done()\n",
        "            return self._get_state(), reward, done, {}\n",
        "\n",
        "    def step_reviewer(self, feedback):\n",
        "        missing_percent_after = self.df.isnull().mean().mean()\n",
        "        if np.isnan(missing_percent_after):\n",
        "            missing_percent_after = 1.0\n",
        "\n",
        "        if missing_percent_after < self.missing_percent_before_feedback:\n",
        "            reward = (self.missing_percent_before_feedback - missing_percent_after) * 10\n",
        "        elif self.df.empty or self.df.isnull().all().all():\n",
        "            reward = -1.0\n",
        "        else:\n",
        "            reward = -0.5\n",
        "\n",
        "        self.missing_percent_before_feedback = missing_percent_after\n",
        "        done = self._check_done()\n",
        "        return self._get_state(), reward, done, {}\n",
        "\n",
        "    def _calculate_reward_coder(self):\n",
        "        if self.df.empty or self.df.isnull().all().all():\n",
        "            reward = -1.0\n",
        "        else:\n",
        "            missing_percent = self.df.isnull().mean().mean()\n",
        "            reward = -missing_percent\n",
        "        return reward\n",
        "\n",
        "    def _check_done(self):\n",
        "        if self.df.empty or self.df.isnull().all().all():\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def generate_analytic_report(self):\n",
        "        prompt = \"\"\"\n",
        "        Você é um assistente de dados. Com base no DataFrame 'df' atual e no processo de limpeza que foi realizado,\n",
        "        gere um relatório analítico com as seguintes seções:\n",
        "\n",
        "        1. Descrição do Problema\n",
        "        2. Descrição dos Dados\n",
        "        3. Metodologia\n",
        "        4. Resultados\n",
        "        5. Conclusão\n",
        "\n",
        "        Seja claro, preciso e siga as melhores práticas de análise de dados.\n",
        "        \"\"\"\n",
        "        report = self.llm_client.generate_feedback(prompt)\n",
        "        return report\n",
        "\n",
        "    def evaluate_report(self, report):\n",
        "        prompt = f\"\"\"\n",
        "        Avalie o seguinte relatório em cada um dos critérios listados.\n",
        "        Retorne as notas de forma estruturada (formato JSON), com cada critério tendo uma nota de 0 a 10.\n",
        "        Critérios:\n",
        "        - Descrição do Problema: Clareza, Acurácia\n",
        "        - Descrição dos Dados: Completude, Qualidade_dados, Visualizacao\n",
        "        - Metodologia: Abordagem, Justificativa, Implementacao\n",
        "        - Resultados: Precisao, Compreensao, Visualizacao\n",
        "        - Conclusao: Resumo, Implicacoes, Recomendacoes\n",
        "\n",
        "        Relatório:\n",
        "        {report}\n",
        "        \"\"\"\n",
        "\n",
        "        feedback = self.llm_client.generate_feedback(prompt)\n",
        "        try:\n",
        "            scores = json.loads(feedback)\n",
        "        except:\n",
        "            scores = {\n",
        "                \"descricao_problema\": {\"clareza\":5,\"acuracia\":5},\n",
        "                \"descricao_dados\": {\"completude\":5,\"qualidade_dados\":5,\"visualizacao\":5},\n",
        "                \"metodologia\": {\"abordagem\":5,\"justificativa\":5,\"implementacao\":5},\n",
        "                \"resultados\": {\"precisao\":5,\"compreensao\":5,\"visualizacao\":5},\n",
        "                \"conclusao\": {\"resumo\":5,\"implicacoes\":5,\"recomendacoes\":5}\n",
        "            }\n",
        "\n",
        "        total_score = (scores[\"descricao_problema\"][\"clareza\"] +\n",
        "                       scores[\"descricao_problema\"][\"acuracia\"] +\n",
        "                       scores[\"descricao_dados\"][\"completude\"] +\n",
        "                       scores[\"descricao_dados\"][\"qualidade_dados\"] +\n",
        "                       scores[\"descricao_dados\"][\"visualizacao\"] +\n",
        "                       scores[\"metodologia\"][\"abordagem\"] +\n",
        "                       scores[\"metodologia\"][\"justificativa\"] +\n",
        "                       scores[\"metodologia\"][\"implementacao\"] +\n",
        "                       scores[\"resultados\"][\"precisao\"] +\n",
        "                       scores[\"resultados\"][\"compreensao\"] +\n",
        "                       scores[\"resultados\"][\"visualizacao\"] +\n",
        "                       scores[\"conclusao\"][\"resumo\"] +\n",
        "                       scores[\"conclusao\"][\"implicacoes\"] +\n",
        "                       scores[\"conclusao\"][\"recomendacoes\"])\n",
        "\n",
        "        return total_score\n",
        "\n",
        "    def finalize_evaluation(self):\n",
        "        report = self.generate_analytic_report()\n",
        "        total_score = self.evaluate_report(report)\n",
        "        normalized_score = total_score / 150.0\n",
        "        threshold_score = 135\n",
        "        done = total_score >= threshold_score\n",
        "        return normalized_score, done\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kqyMlCnxhga8"
      },
      "outputs": [],
      "source": [
        "def discretize_state(state, num_states):\n",
        "    state_value = state[0]\n",
        "    if np.isnan(state_value):\n",
        "        state_value = 1.0\n",
        "    state_value = min(max(state_value, 0), 0.999)\n",
        "    return int(state_value * num_states)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0zK0UX72hiol"
      },
      "outputs": [],
      "source": [
        "def train_agents(api_key, num_episodes=30, decay_rate=0.995, min_epsilon=0.1, max_steps_per_episode=50):\n",
        "    llm_client = LLMClient(api_key=api_key)\n",
        "    env = DataCleaningEnv(llm_client, data_folder=broken_data_folder)\n",
        "\n",
        "    num_states = 10\n",
        "    coder = CoderAgent(num_states, len(CoderAgent(0,0).actions))\n",
        "    reviewer = ReviewerAgent(num_states, len(ReviewerAgent(0,0).actions))\n",
        "\n",
        "    best_coder_reward = float('-inf')\n",
        "    best_reviewer_reward = float('-inf')\n",
        "\n",
        "    coder_rewards = []\n",
        "    reviewer_rewards = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for episode in tqdm(range(num_episodes), desc=\"Treinando\", unit=\"ep\"):\n",
        "        state = env.reset()\n",
        "        state_index = discretize_state(state, num_states)\n",
        "        done = False\n",
        "        total_coder_reward = 0\n",
        "        total_reviewer_reward = 0\n",
        "\n",
        "        coder_action_index = coder.select_action(state_index)\n",
        "        reviewer_action_index = reviewer.select_action(state_index)\n",
        "\n",
        "        step_count = 0\n",
        "\n",
        "        while not done and step_count < max_steps_per_episode:\n",
        "            step_count += 1\n",
        "\n",
        "            action_coder = coder.actions[coder_action_index]\n",
        "            prompt = f\"\"\"\n",
        "            Você é um assistente que ajuda a limpar dataframes do pandas.\n",
        "            O dataframe 'df' contém dados com valores faltantes e possivelmente ruídos.\n",
        "            Sua tarefa é: {action_coder}.\n",
        "            Forneça apenas o código Python necessário para realizar essa tarefa no dataframe 'df'.\n",
        "            Não inclua explicações ou uso de 'input()' ou 'import os'.\n",
        "            \"\"\"\n",
        "            code = llm_client.generate_code(prompt)\n",
        "\n",
        "            next_state, reward_coder, done_coder, _ = env.step_coder(code, coder_action_index)\n",
        "            total_coder_reward += reward_coder\n",
        "            next_state_index = discretize_state(next_state, num_states)\n",
        "            next_coder_action_index = coder.select_action(next_state_index)\n",
        "            coder.update(state_index, coder_action_index, reward_coder, next_state_index)\n",
        "\n",
        "            action_reviewer = reviewer.actions[reviewer_action_index]\n",
        "            prompt_feedback = f\"\"\"\n",
        "            O código fornecido foi:\n",
        "            {code}\n",
        "\n",
        "            Dê feedback: {action_reviewer}.\n",
        "            \"\"\"\n",
        "            feedback = llm_client.generate_feedback(prompt_feedback)\n",
        "\n",
        "            next_state_reviewer, reward_reviewer, done_reviewer, _ = env.step_reviewer(feedback)\n",
        "            total_reviewer_reward += reward_reviewer\n",
        "            next_reviewer_state_index = discretize_state(next_state_reviewer, num_states)\n",
        "            next_reviewer_action_index = reviewer.select_action(next_reviewer_state_index)\n",
        "            reviewer.update(state_index, reviewer_action_index, reward_reviewer, next_reviewer_state_index, next_reviewer_action_index)\n",
        "\n",
        "            state_index = next_state_index\n",
        "            coder_action_index = next_coder_action_index\n",
        "            reviewer_action_index = next_reviewer_action_index\n",
        "\n",
        "            done = done_coder or done_reviewer\n",
        "\n",
        "        coder.decay_epsilon(decay_rate, min_epsilon)\n",
        "        reviewer.decay_epsilon(decay_rate, min_epsilon)\n",
        "\n",
        "        coder_rewards.append(total_coder_reward)\n",
        "        reviewer_rewards.append(total_reviewer_reward)\n",
        "\n",
        "        if total_coder_reward > best_coder_reward:\n",
        "            best_coder_reward = total_coder_reward\n",
        "            np.save(os.path.join(models_folder, 'best_coder_q_table.npy'), coder.q_table)\n",
        "\n",
        "        if total_reviewer_reward > best_reviewer_reward:\n",
        "            best_reviewer_reward = total_reviewer_reward\n",
        "            np.save(os.path.join(models_folder, 'best_reviewer_q_table.npy'), reviewer.q_table)\n",
        "\n",
        "    np.save(os.path.join(models_folder, 'final_coder_q_table.npy'), coder.q_table)\n",
        "    np.save(os.path.join(models_folder, 'final_reviewer_q_table.npy'), reviewer.q_table)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"Tempo total de treinamento: {elapsed_time:.2f} segundos\")\n",
        "\n",
        "    plt.plot(np.arange(num_episodes), coder_rewards, label='Codificador')\n",
        "    plt.plot(np.arange(num_episodes), reviewer_rewards, label='Revisor')\n",
        "    plt.xlabel('Episódios')\n",
        "    plt.ylabel('Recompensa')\n",
        "    plt.legend()\n",
        "    plt.title('Recompensas ao longo dos Episódios')\n",
        "    plt.savefig(os.path.join(logs_folder, 'recompensas.png'))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"Distribuição de ações do Codificador após o treinamento:\")\n",
        "    for i, action_name in enumerate(coder.actions):\n",
        "        print(f\"Ação {i} ({action_name}): {coder.action_counts[i]} seleções\")\n",
        "\n",
        "    print(\"Distribuição de ações do Revisor após o treinamento:\")\n",
        "    for i, action_name in enumerate(reviewer.actions):\n",
        "        print(f\"Ação {i} ({action_name}): {reviewer.action_counts[i]} seleções\")\n",
        "\n",
        "    final_score, task_complete = env.finalize_evaluation()\n",
        "    print(f\"Pontuação final do relatório: {final_score*150:.2f} de 150\")\n",
        "    print(\"Tarefa concluída?\" , \"Sim\" if task_complete else \"Não\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "9x5lhpAOhkuC",
        "outputId": "0c4efebc-38d2-4632-eb7f-9eaba043d27c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-39ae2e1b8dcf>:20: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(filepath)\n",
            "<ipython-input-6-cd806d6eca4f>:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
            "  df_broken.iat[row, col] = np.nan\n",
            "Treinando:  10%|█         | 1/10 [00:55<08:16, 55.13s/ep]<ipython-input-9-4888254babd3>:14: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  self.df = pd.read_csv(data_file)\n",
            "Treinando:  60%|██████    | 6/10 [05:06<03:18, 49.69s/ep]<ipython-input-9-4888254babd3>:14: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  self.df = pd.read_csv(data_file)\n",
            "Treinando: 100%|██████████| 10/10 [08:46<00:00, 52.67s/ep]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tempo total de treinamento: 526.75 segundos\n",
            "Distribuição de ações do Codificador após o treinamento:\n",
            "Ação 0 (Remover linhas com valores nulos em 'df'): 52.0 seleções\n",
            "Ação 1 (Preencher valores nulos em colunas numéricas de 'df' com a média): 17.0 seleções\n",
            "Ação 2 (Preencher valores nulos em 'df' com zero): 20.0 seleções\n",
            "Ação 3 (Remover colunas com muitos valores nulos em 'df'): 21.0 seleções\n",
            "Distribuição de ações do Revisor após o treinamento:\n",
            "Ação 0 (O código está correto): 23.0 seleções\n",
            "Ação 1 (O código tem erros de sintaxe): 26.0 seleções\n",
            "Ação 2 (O código não resolve o problema): 36.0 seleções\n",
            "Ação 3 (O código é ineficiente): 25.0 seleções\n",
            "Pontuação final do relatório: 70.00 de 150\n",
            "Tarefa concluída? Não\n"
          ]
        }
      ],
      "source": [
        "SUA_CHAVE_API = \" \"\n",
        "\n",
        "prepare_broken_data()\n",
        "\n",
        "train_agents(api_key=SUA_CHAVE_API, num_episodes=10, decay_rate=0.995, min_epsilon=0.1, max_steps_per_episode=10)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
